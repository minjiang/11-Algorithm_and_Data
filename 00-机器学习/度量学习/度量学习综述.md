# 度量学习（metric learning）
卡内基梅隆大学机器学习系的邢波教授于2003年提出了距离度量学习。

一个好的距离度量能够根据数据的结构与分布适用于不同的应用。距离的度量对众多机器学习方法的性能都起到了决定性作用：例如在分类方法中，K近邻分类器、使用了高斯核的核方法；在聚类方法中，K均值聚类、谱聚类方法都与距离度量密切相关。
几乎每种线性距离度量学习方法都对应着一类降维策略。在意识到距离度量学习和降维的关系之后，研究者们提出了很多能够直接进行降维或者利用降维能力简化计算的距离度量学习方法。

配合“参考资料”来看。

## 概念
一般的距离度量学习针对度量矩阵M展开。

度量矩阵的对称正定性，必然存在正交基P，使得M=PP~T ，故对度量矩阵M的学习，等效于学习一个线性空间变换矩阵P。

更进一步地，若M是一个低秩矩阵，那么存在正交基P，该正交基可以作为降维矩阵使用。也即低秩距离度量学习可以衍生出一个降维方法。

## 相关名词
必连（must-link）和勿连（cannot link）约束集概念：分别记为S和D，即相似样本组成的样本对属于必连约束集、相异样本对属于勿连约束集。
必连、勿连约束往往来自于样本的标记信息，而且约束所有的样本，故而使用必连、勿连约束的距离度量学习方法往往是全局度量学习方法。


## 性质
一般来说，对于任意样本x, y, z而言，距离度量函数需要满足：

1）自反（任意样本到自身的距离为0）
 
2）对称（x到y的距离等于y到x的距离）
 
3）非负（任意样本对之间的距离大于等于0）
 
4）直递（三个样本之间的距离满足三角不等式）等性质

## 度量的种类
常用的有闵可夫斯基距离（欧几里得距离、曼哈顿距离、切比雪夫距离均为其特例）、马氏距离、海明距离等距离度量函数。
针对某些特定问题的衍生距离度量，例如，动态时间规整距离DTW, 推土机距离EMD等。

## 使用指南
1)欧氏距离是众多数据挖掘应用中使用最多的距离度量，但是欧氏距离仅适用于特征空间中超球结构的数据集，对于超立方体结构、超椭球结构的数据集效果不太理想。

2）余弦距离在文本检索中有优秀的表现，但是其预先假设了数据集每一维度都是等权重的，这一特性显然限制了余弦距离的应用范围。
例子：LMNN学习得到的度量旨在局部区域将同类样本点拉近、异类样本点排斥开，并在同类和异类样本之间建立一个边界区域以便于kNN取得较好的分类效果。

## 度量学习与表征学习的关联
在图像检索中，其基本问题是如何度量图像间的相关度，这可分解为图像表征学习和距离测度学习。直观地讲，为提高相关性度量质量，我们可以优化图像标注学习，也可以优化距离测度学习。
然而，与其他视觉任务不同，图像检索面对的数据库规模大，对检索相应时间苛刻，因此一般采用简单的距离测度，比如L1距离或L2距离，这样方便通过施加稀疏性约束来引入倒排索引结构。所以，在很多图像检索方法中，相对于距离测度学习，大家一般更关注在图像表征学习上。

我把这个称为“度量学习的核心有二：特征表达和距离”。


# 参考资料
度量学习参考资料